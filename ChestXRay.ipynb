{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Download and Extraction\n",
        "\n",
        "In this section, we are downloading the chest X-ray dataset for pneumonia detection from Kaggle and extract it for further processing. We'll use the Kaggle API to facilitate the download and the Python `ZipFile` library for extraction.\n",
        "\n",
        "### Kaggle Configuration\n",
        "\n",
        "Before proceeding, we have to make sure you have set up your Kaggle API credentials. You can configure your API credentials by setting the `KAGGLE_CONFIG_DIR` environment variable to the directory containing your `kaggle.json` file."
      ],
      "metadata": {
        "id": "ULBPmzOmFi1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile"
      ],
      "metadata": {
        "id": "n-HMi4Bm2eJC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4x5hZPL3J0ZR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__XhdJfcvQo3",
        "outputId": "4569d5e2-4be9-480c-b560-c616ef1d23bb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Downloading chest-xray-pneumonia.zip to /content\n",
            "100% 2.29G/2.29G [01:51<00:00, 20.2MB/s]\n",
            "100% 2.29G/2.29G [01:51<00:00, 22.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the dataset is downloaded, we'll extract its contents into a directory named \"chest_xray.\""
      ],
      "metadata": {
        "id": "NUj31x6NGGbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with ZipFile('/content/chest-xray-pneumonia.zip','r') as zipobj:\n",
        "  zipobj.extractall(\"/content/chest_xray\")"
      ],
      "metadata": {
        "id": "t1MTqBCg2zrz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVz9B3bT0-2Y",
        "outputId": "924b9e85-8039-4d39-f89d-a084716b4276"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Libraries\n",
        "\n",
        "We start by importing the essential libraries required for this project. These libraries include TensorFlow, Keras, NumPy, Pandas, and additional utilities for image processing.\n"
      ],
      "metadata": {
        "id": "P92Wrd61GczH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.utils import image_dataset_from_directory\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.layers import LeakyReLU\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Add, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental import preprocessing"
      ],
      "metadata": {
        "id": "JHSflhgl3zek"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the Dataset\n",
        "\n",
        "We start by loading the dataset from the specified directory using `image_dataset_from_directory`. This function allows us to load images directly from directories and infer labels based on subdirectories. We are loading training, testing and validation datasets.\n",
        "\n",
        "### Data Normalization\n",
        "To prepare the data for training, we normalize the pixel values of the images. Normalization typically involves scaling pixel values to a range between 0 and 1. This helps in better convergence during model training. We have applied the same to the test and validation dataset as well"
      ],
      "metadata": {
        "id": "pDSgUkPnGrK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = image_dataset_from_directory(\"/content/chest_xray/chest_xray/train\",\n",
        "                             labels=\"inferred\",\n",
        "                             label_mode=\"categorical\",\n",
        "                             class_names=[\"NORMAL\",\"PNEUMONIA\"],\n",
        "                             batch_size=32,\n",
        "                             image_size=(512,512),\n",
        "                             color_mode=\"grayscale\",\n",
        "                             seed=42)\n",
        "train_dataset = train_dataset.map(lambda x, y: (x / 255.0, y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Hp1dZa7xSpM",
        "outputId": "a5162547-49e1-48e9-f848-df99469d47ed"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5216 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_dataset = image_dataset_from_directory(\"/content/chest_xray/chest_xray/val\",\n",
        "                             labels=\"inferred\",\n",
        "                             label_mode=\"categorical\",\n",
        "                             class_names=[\"NORMAL\",\"PNEUMONIA\"],\n",
        "                            #  batch_size=32,\n",
        "                             image_size=(512,512),\n",
        "                             color_mode=\"grayscale\",\n",
        "                             seed=42)\n",
        "validation_dataset = validation_dataset.map(lambda x, y: (x / 255.0, y))"
      ],
      "metadata": {
        "id": "8soBcAVXxVRb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa64c444-fbe0-4666-a243-3a926da38652"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 16 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = image_dataset_from_directory(\"/content/chest_xray/chest_xray/test\",\n",
        "                             labels=\"inferred\",\n",
        "                             label_mode=\"categorical\",\n",
        "                             class_names=[\"NORMAL\",\"PNEUMONIA\"],\n",
        "                            #  batch_size=32,\n",
        "                             image_size=(512, 512),\n",
        "                             color_mode=\"grayscale\",\n",
        "                             seed=42)\n",
        "test_dataset = test_dataset.map(lambda x, y: (x / 255.0, y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTPDJ7l6xWtC",
        "outputId": "93dd8284-9dac-48de-a2c0-62ce87320941"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 624 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building and Training the Classification Model\n",
        "\n",
        "In this section, we define the architecture of our chest X-ray classification model and train it using the preprocessed training dataset. Let's break down the steps involved in constructing and training the model:\n",
        "\n",
        "### Model Architecture\n",
        "\n",
        "We construct a convolutional neural network (CNN) using Keras to learn features from chest X-ray images. Below is a detailed explanation of the model layers:\n",
        "The model consists of convolutional layers with ReLU activation functions and\n",
        "\n",
        "- LeakyReLU layers to introduce non-linearity.\n",
        "\n",
        "- Max-pooling layers downsample the feature maps.\n",
        "\n",
        "- Dropout layers are added to prevent overfitting.\n",
        "\n",
        "### Model Compilation\n",
        "We compile the model by specifying the optimizer, loss function, and evaluation metric:\n",
        "\n",
        "- We use the Adam optimizer.\n",
        "\n",
        "- Binary cross-entropy loss is chosen for binary classification.\n",
        "\n",
        "- Accuracy is the evaluation metric.\n",
        "\n",
        "### Training the Model\n",
        "The model is trained using the training dataset, with validation data provided for monitoring training progress:\n",
        "\n",
        "We train the model for 100 epochs."
      ],
      "metadata": {
        "id": "kkrtU60k_L-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(layers.Conv2D(32, kernel_size=(3,3), activation=\"relu\", input_shape = (256, 256, 1)))\n",
        "model.add(LeakyReLU(alpha=0.2))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Conv2D(64, kernel_size=(3,3), activation=\"relu\"))\n",
        "model.add(LeakyReLU(alpha=0.2))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Conv2D(128, kernel_size=(3,3), activation=\"relu\"))\n",
        "model.add(LeakyReLU(alpha=0.2))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Conv2D(256, kernel_size=(3,3), activation=\"relu\"))\n",
        "model.add(LeakyReLU(alpha=0.2))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Conv2D(128, kernel_size=(3,3), activation=\"relu\"))\n",
        "model.add(LeakyReLU(alpha=0.2))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Conv2D(64, kernel_size=(3,3), activation=\"relu\"))\n",
        "model.add(LeakyReLU(alpha=0.2))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "model.add(layers.Dropout(0.5))\n",
        "# model.add(layers.Conv2D(32, kernel_size=(3,3), activation=\"relu\"))\n",
        "# model.add(LeakyReLU(alpha=0.2))\n",
        "# model.add(layers.MaxPooling2D(2,2))\n",
        "# model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(32, activation=\"relu\"))\n",
        "model.add(layers.Dense(2, activation=\"sigmoid\"))\n",
        "\n",
        "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "# model.summary()\n",
        "history = model.fit(train_dataset, epochs=100, validation_data=validation_dataset)"
      ],
      "metadata": {
        "id": "qdyTSjc2xYDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"content/chest_xray/model2.keras\")"
      ],
      "metadata": {
        "id": "ahVjnMM4WLBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation on Test Data\n",
        "\n",
        "In this section, we evaluate the performance of our chest X-ray classification model on a separate test dataset. The model has been trained on the training dataset, and now we assess how well it generalizes to unseen data.\n",
        "\n",
        "### Model Evaluation Code\n",
        "\n",
        "We use the `evaluate` method to assess the model's performance on the test dataset:"
      ],
      "metadata": {
        "id": "Rk4L13UFAJwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KMNUyYOTT-v",
        "outputId": "46d1675f-51e6-407f-a249-f5c73480ba6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 2s 74ms/step - loss: 0.7662 - accuracy: 0.8029\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7662030458450317, 0.8028846383094788]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation Output\n",
        "Upon running the evaluation code, we obtain the following output:\n",
        "\n",
        "The evaluation was performed on 20 batches of test data.\n",
        "loss: `0.7662` represents the computed loss value.\n",
        "accuracy: `0.8029` indicates the accuracy of the model on the test dataset.\n",
        "\n",
        "An accuracy of approximately 80.29% suggests that the model is capable of distinguishing between normal and pneumonia cases with a good level of accuracy."
      ],
      "metadata": {
        "id": "AFpQJd5oAUUy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Residual Block for CNN\n",
        "\n",
        "In this section, we define a custom residual block function for our CNN arhitecture to deal with the vanishing gradient problem.\n",
        "\n",
        "We have defined a custom residual block function, `residual_block`, which takes the following parameters:\n",
        "\n",
        "- `x`: Input tensor.\n",
        "- `filters`: The number of filters in the convolutional layers.\n",
        "- `kernel_size`: The size of the convolutional kernel.\n",
        "- `stride`: The stride for the convolutional layers (default is 1).\n",
        "\n",
        "\n",
        "we are using the `residual_block` function to create a residual block within our CNN architecture. These blocks help in the training of deep networks and enable the construction of deep CNNs with improved gradient flow."
      ],
      "metadata": {
        "id": "_LshT6o6BFcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_block(x, filters, kernel_size, stride=1):\n",
        "    identity = x\n",
        "\n",
        "    x = Conv2D(filters, kernel_size, strides=stride, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters, kernel_size, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    if stride != 1 or identity.shape[-1] != filters:\n",
        "        identity = Conv2D(filters, (1, 1), strides=stride, padding='same')(identity)\n",
        "\n",
        "    x = Add()([x, identity])\n",
        "    x = Activation('relu')(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "JwycO3nnAk_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a Residual Network (ResNet) Model\n",
        "\n",
        "We define a convolutional neural network (CNN) model using the ResNet architecture. This helps us to train very deep networks effectively by employing residual blocks, which help address the vanishing gradient problem.\n",
        "\n",
        "### Model Architecture\n",
        "\n",
        "We define a function `build_resnet` that constructs the ResNet model. Here's an overview of the model architecture:\n",
        "\n",
        "1. **Input Layer**:\n",
        "   - The model starts with an input layer that takes images of shape `(256, 256, 1)`.\n",
        "\n",
        "2. **Initial Convolution and Pooling**:\n",
        "   - A 2D convolutional layer with 64 filters, a `(7, 7)` kernel size, and `strides=(2, 2)` is applied.\n",
        "   - Batch normalization and ReLU activation follow the convolution.\n",
        "   - A max-pooling layer with `(3, 3)` pooling size and `strides=(2, 2)` is used for downsampling.\n",
        "\n",
        "3. **Residual Blocks**:\n",
        "   - We employ a series of residual blocks using the `residual_block` function:\n",
        "     - Two residual blocks with 64 filters and `(3, 3)` kernel size.\n",
        "     - Two residual blocks with 128 filters and `(3, 3)` kernel size, with a stride of 2 for downsampling.\n",
        "     - Two residual blocks with 256 filters and `(3, 3)` kernel size, with a stride of 2 for downsampling.\n",
        "     - Two residual blocks with 512 filters and `(3, 3)` kernel size, with a stride of 2 for downsampling.\n",
        "\n",
        "4. **Global Average Pooling and Output Layer**:\n",
        "   - Global average pooling is applied to reduce the spatial dimensions.\n",
        "   - A fully connected layer with softmax activation produces the final output.\n",
        "\n",
        "### Model Compilation\n",
        "\n",
        "We compile the ResNet model with the following settings:\n",
        "- We use the Adam optimizer.\n",
        "- Categorical cross-entropy loss is chosen for multi-class classification.\n",
        "- Accuracy is used as the evaluation metric.\n",
        "\n",
        "### Model Summary\n",
        "To get an overview of the model's architecture and the number of trainable parameters, we print the model summary using model.summary()."
      ],
      "metadata": {
        "id": "Zl0Z5UT0B2jA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_resnet(input_shape, num_classes):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv2D(64, (7, 7), padding='same', strides=(2, 2))(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "\n",
        "    x = residual_block(x, 64, (3, 3))\n",
        "    x = residual_block(x, 64, (3, 3))\n",
        "    x = residual_block(x, 128, (3, 3), stride=2)\n",
        "    x = residual_block(x, 128, (3, 3))\n",
        "    x = residual_block(x, 256, (3, 3), stride=2)\n",
        "    x = residual_block(x, 256, (3, 3))\n",
        "    x = residual_block(x, 512, (3, 3), stride=2)\n",
        "    x = residual_block(x, 512, (3, 3))\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=input_tensor, outputs=x)\n",
        "    return model\n",
        "\n",
        "input_shape = (256, 256, 1)\n",
        "num_classes = 2\n",
        "resnet_model = build_resnet(input_shape, num_classes)\n",
        "\n",
        "resnet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "resnet_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9wwj8FXCxoD",
        "outputId": "8edfb491-70c0-4de3-a135-ff9348f2ae45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 256, 256, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 128, 128, 64  3200        ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 128, 128, 64  256        ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 128, 128, 64  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 64, 64, 64)   0           ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 64, 64, 64)   36928       ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 64, 64, 64)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 64, 64, 64)   36928       ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 64, 64, 64)   0           ['batch_normalization_2[0][0]',  \n",
            "                                                                  'max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 64, 64, 64)   0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 64, 64, 64)   36928       ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 64, 64, 64)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 64, 64, 64)   36928       ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 64, 64, 64)   0           ['batch_normalization_4[0][0]',  \n",
            "                                                                  'activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 64, 64, 64)   0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 32, 32, 128)  73856       ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 32, 32, 128)  0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 32, 32, 128)  147584      ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 32, 32, 128)  8320        ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 32, 32, 128)  0           ['batch_normalization_6[0][0]',  \n",
            "                                                                  'conv2d_7[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 32, 32, 128)  0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 32, 32, 128)  147584      ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 32, 32, 128)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 32, 32, 128)  147584      ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 32, 32, 128)  0           ['batch_normalization_8[0][0]',  \n",
            "                                                                  'activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 32, 32, 128)  0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 16, 16, 256)  295168      ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_10[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 16, 16, 256)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 16, 16, 256)  590080      ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 16, 16, 256)  1024       ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 16, 16, 256)  33024       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_10[0][0]', \n",
            "                                                                  'conv2d_12[0][0]']              \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 16, 16, 256)  0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 16, 16, 256)  590080      ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 16, 16, 256)  1024       ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 16, 16, 256)  0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 16, 16, 256)  590080      ['activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 16, 16, 256)  1024       ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_12[0][0]', \n",
            "                                                                  'activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 16, 16, 256)  0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 8, 8, 512)    1180160     ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 8, 8, 512)    0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 8, 8, 512)    2359808     ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 8, 8, 512)    131584      ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 8, 8, 512)    0           ['batch_normalization_14[0][0]', \n",
            "                                                                  'conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 8, 8, 512)    0           ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 8, 8, 512)    2359808     ['activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 8, 8, 512)    0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 8, 8, 512)    2359808     ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 8, 8, 512)    0           ['batch_normalization_16[0][0]', \n",
            "                                                                  'activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 8, 8, 512)    0           ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 32768)        0           ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 2)            65538       ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 11,246,594\n",
            "Trainable params: 11,238,786\n",
            "Non-trainable params: 7,808\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training\n",
        "\n",
        "We train the ResNet model on the training dataset using the `fit` method. The training process includes 100 epochs to iteratively learn from the data:"
      ],
      "metadata": {
        "id": "HG4F_PGfC9CS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = resnet_model.fit(train_dataset, epochs=100, validation_data=validation_dataset)\n",
        "resnet_model.save(\"/content/drive/MyDrive/ChestXraay/resne_model.keras\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcIql5fRC6eL",
        "outputId": "4d2d126a-95e6-409e-c548-2db49096dc5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "163/163 [==============================] - 63s 217ms/step - loss: 0.8969 - accuracy: 0.9053 - val_loss: 3.3564 - val_accuracy: 0.5000\n",
            "Epoch 2/100\n",
            "163/163 [==============================] - 35s 204ms/step - loss: 0.1981 - accuracy: 0.9442 - val_loss: 9.6286 - val_accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "163/163 [==============================] - 37s 213ms/step - loss: 0.0933 - accuracy: 0.9701 - val_loss: 13.8233 - val_accuracy: 0.5000\n",
            "Epoch 4/100\n",
            "163/163 [==============================] - 37s 221ms/step - loss: 0.0735 - accuracy: 0.9749 - val_loss: 0.5602 - val_accuracy: 0.8750\n",
            "Epoch 5/100\n",
            "163/163 [==============================] - 36s 206ms/step - loss: 0.0714 - accuracy: 0.9755 - val_loss: 18.6334 - val_accuracy: 0.5000\n",
            "Epoch 6/100\n",
            "163/163 [==============================] - 36s 215ms/step - loss: 0.3145 - accuracy: 0.9381 - val_loss: 128.4397 - val_accuracy: 0.5000\n",
            "Epoch 7/100\n",
            "163/163 [==============================] - 36s 209ms/step - loss: 0.0848 - accuracy: 0.9712 - val_loss: 0.1234 - val_accuracy: 0.9375\n",
            "Epoch 8/100\n",
            "163/163 [==============================] - 36s 205ms/step - loss: 0.0376 - accuracy: 0.9866 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "163/163 [==============================] - 38s 227ms/step - loss: 0.0402 - accuracy: 0.9850 - val_loss: 3.3154 - val_accuracy: 0.5625\n",
            "Epoch 10/100\n",
            "163/163 [==============================] - 35s 208ms/step - loss: 0.0377 - accuracy: 0.9870 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "163/163 [==============================] - 35s 208ms/step - loss: 0.0279 - accuracy: 0.9896 - val_loss: 0.3189 - val_accuracy: 0.9375\n",
            "Epoch 12/100\n",
            "163/163 [==============================] - 37s 213ms/step - loss: 0.0265 - accuracy: 0.9900 - val_loss: 0.1056 - val_accuracy: 0.9375\n",
            "Epoch 13/100\n",
            "163/163 [==============================] - 36s 209ms/step - loss: 0.0142 - accuracy: 0.9937 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "163/163 [==============================] - 37s 221ms/step - loss: 0.0069 - accuracy: 0.9971 - val_loss: 0.6882 - val_accuracy: 0.8125\n",
            "Epoch 15/100\n",
            "163/163 [==============================] - 35s 207ms/step - loss: 0.1216 - accuracy: 0.9818 - val_loss: 418.5020 - val_accuracy: 0.5000\n",
            "Epoch 16/100\n",
            "163/163 [==============================] - 37s 215ms/step - loss: 0.1622 - accuracy: 0.9651 - val_loss: 3.8708 - val_accuracy: 0.5000\n",
            "Epoch 17/100\n",
            "163/163 [==============================] - 35s 207ms/step - loss: 0.0456 - accuracy: 0.9849 - val_loss: 0.7169 - val_accuracy: 0.7500\n",
            "Epoch 18/100\n",
            "163/163 [==============================] - 35s 207ms/step - loss: 0.0167 - accuracy: 0.9939 - val_loss: 0.1769 - val_accuracy: 0.9375\n",
            "Epoch 19/100\n",
            "163/163 [==============================] - 37s 211ms/step - loss: 0.0092 - accuracy: 0.9967 - val_loss: 0.1380 - val_accuracy: 0.9375\n",
            "Epoch 20/100\n",
            "163/163 [==============================] - 35s 207ms/step - loss: 0.0045 - accuracy: 0.9981 - val_loss: 0.1058 - val_accuracy: 0.9375\n",
            "Epoch 21/100\n",
            "163/163 [==============================] - 35s 205ms/step - loss: 0.0140 - accuracy: 0.9939 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "163/163 [==============================] - 35s 206ms/step - loss: 0.0324 - accuracy: 0.9887 - val_loss: 14.5653 - val_accuracy: 0.5625\n",
            "Epoch 23/100\n",
            "163/163 [==============================] - 37s 208ms/step - loss: 0.0448 - accuracy: 0.9875 - val_loss: 2.7211 - val_accuracy: 0.6250\n",
            "Epoch 24/100\n",
            "163/163 [==============================] - 35s 209ms/step - loss: 0.0243 - accuracy: 0.9914 - val_loss: 0.1052 - val_accuracy: 0.9375\n",
            "Epoch 25/100\n",
            "163/163 [==============================] - 38s 219ms/step - loss: 0.0445 - accuracy: 0.9885 - val_loss: 15.4832 - val_accuracy: 0.5000\n",
            "Epoch 26/100\n",
            "163/163 [==============================] - 37s 210ms/step - loss: 0.0465 - accuracy: 0.9885 - val_loss: 0.0932 - val_accuracy: 0.8750\n",
            "Epoch 27/100\n",
            "163/163 [==============================] - 36s 213ms/step - loss: 0.0160 - accuracy: 0.9952 - val_loss: 0.2416 - val_accuracy: 0.8750\n",
            "Epoch 28/100\n",
            "163/163 [==============================] - 35s 206ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 6.8018e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "163/163 [==============================] - 35s 206ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.1448 - val_accuracy: 0.9375\n",
            "Epoch 30/100\n",
            "163/163 [==============================] - 38s 224ms/step - loss: 0.0219 - accuracy: 0.9939 - val_loss: 0.2876 - val_accuracy: 0.8750\n",
            "Epoch 31/100\n",
            "163/163 [==============================] - 35s 206ms/step - loss: 0.0146 - accuracy: 0.9948 - val_loss: 0.4210 - val_accuracy: 0.9375\n",
            "Epoch 32/100\n",
            "163/163 [==============================] - 35s 205ms/step - loss: 0.0296 - accuracy: 0.9916 - val_loss: 0.3863 - val_accuracy: 0.8750\n",
            "Epoch 33/100\n",
            "163/163 [==============================] - 36s 213ms/step - loss: 0.0365 - accuracy: 0.9896 - val_loss: 1.0535 - val_accuracy: 0.7500\n",
            "Epoch 34/100\n",
            "163/163 [==============================] - 35s 207ms/step - loss: 0.0260 - accuracy: 0.9933 - val_loss: 0.6075 - val_accuracy: 0.8125\n",
            "Epoch 35/100\n",
            "163/163 [==============================] - 36s 206ms/step - loss: 0.0229 - accuracy: 0.9941 - val_loss: 0.0602 - val_accuracy: 0.9375\n",
            "Epoch 36/100\n",
            "163/163 [==============================] - 38s 223ms/step - loss: 0.0427 - accuracy: 0.9904 - val_loss: 0.2017 - val_accuracy: 0.8750\n",
            "Epoch 37/100\n",
            "163/163 [==============================] - 34s 202ms/step - loss: 0.0248 - accuracy: 0.9937 - val_loss: 0.3220 - val_accuracy: 0.9375\n",
            "Epoch 38/100\n",
            "163/163 [==============================] - 36s 210ms/step - loss: 0.0367 - accuracy: 0.9908 - val_loss: 6.4278 - val_accuracy: 0.5625\n",
            "Epoch 39/100\n",
            "163/163 [==============================] - 34s 200ms/step - loss: 0.0206 - accuracy: 0.9941 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "163/163 [==============================] - 34s 202ms/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.2831 - val_accuracy: 0.8750\n",
            "Epoch 41/100\n",
            "163/163 [==============================] - 39s 229ms/step - loss: 0.0145 - accuracy: 0.9956 - val_loss: 0.0368 - val_accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "163/163 [==============================] - 34s 202ms/step - loss: 0.0079 - accuracy: 0.9985 - val_loss: 9.2645e-04 - val_accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "163/163 [==============================] - 36s 212ms/step - loss: 0.0316 - accuracy: 0.9923 - val_loss: 0.6030 - val_accuracy: 0.8750\n",
            "Epoch 44/100\n",
            "163/163 [==============================] - 34s 202ms/step - loss: 0.0198 - accuracy: 0.9948 - val_loss: 6.3386 - val_accuracy: 0.5625\n",
            "Epoch 45/100\n",
            "163/163 [==============================] - 36s 211ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 1.3780 - val_accuracy: 0.8125\n",
            "Epoch 46/100\n",
            "163/163 [==============================] - 36s 210ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "163/163 [==============================] - 37s 217ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 3.8284 - val_accuracy: 0.6875\n",
            "Epoch 48/100\n",
            "163/163 [==============================] - 35s 205ms/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 29.1736 - val_accuracy: 0.5000\n",
            "Epoch 49/100\n",
            "163/163 [==============================] - 37s 211ms/step - loss: 0.0135 - accuracy: 0.9960 - val_loss: 0.0377 - val_accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "163/163 [==============================] - 35s 205ms/step - loss: 0.0023 - accuracy: 0.9990 - val_loss: 0.3575 - val_accuracy: 0.8750\n",
            "Epoch 51/100\n",
            "163/163 [==============================] - 37s 211ms/step - loss: 0.0102 - accuracy: 0.9973 - val_loss: 4.9973 - val_accuracy: 0.5000\n",
            "Epoch 52/100\n",
            "163/163 [==============================] - 36s 214ms/step - loss: 0.0282 - accuracy: 0.9937 - val_loss: 4.6762 - val_accuracy: 0.5625\n",
            "Epoch 53/100\n",
            "163/163 [==============================] - 36s 205ms/step - loss: 0.0448 - accuracy: 0.9904 - val_loss: 1.4478 - val_accuracy: 0.8750\n",
            "Epoch 54/100\n",
            "163/163 [==============================] - 36s 212ms/step - loss: 0.0612 - accuracy: 0.9904 - val_loss: 53.3055 - val_accuracy: 0.5000\n",
            "Epoch 55/100\n",
            "163/163 [==============================] - 36s 206ms/step - loss: 0.0164 - accuracy: 0.9952 - val_loss: 4.2553 - val_accuracy: 0.6250\n",
            "Epoch 56/100\n",
            "163/163 [==============================] - 35s 209ms/step - loss: 0.0179 - accuracy: 0.9969 - val_loss: 1.4088 - val_accuracy: 0.8750\n",
            "Epoch 57/100\n",
            "163/163 [==============================] - 35s 205ms/step - loss: 0.0087 - accuracy: 0.9987 - val_loss: 1.1245 - val_accuracy: 0.8125\n",
            "Epoch 58/100\n",
            "163/163 [==============================] - 37s 221ms/step - loss: 0.0023 - accuracy: 0.9990 - val_loss: 2.9909 - val_accuracy: 0.6250\n",
            "Epoch 59/100\n",
            "163/163 [==============================] - 36s 207ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "163/163 [==============================] - 37s 216ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.8229 - val_accuracy: 0.9375\n",
            "Epoch 61/100\n",
            "163/163 [==============================] - 35s 205ms/step - loss: 6.2646e-05 - accuracy: 1.0000 - val_loss: 1.0900 - val_accuracy: 0.9375\n",
            "Epoch 62/100\n",
            "163/163 [==============================] - 35s 207ms/step - loss: 9.7306e-06 - accuracy: 1.0000 - val_loss: 1.0476 - val_accuracy: 0.9375\n",
            "Epoch 63/100\n",
            "163/163 [==============================] - 37s 219ms/step - loss: 7.0583e-06 - accuracy: 1.0000 - val_loss: 1.0216 - val_accuracy: 0.9375\n",
            "Epoch 64/100\n",
            "163/163 [==============================] - 35s 205ms/step - loss: 5.3742e-06 - accuracy: 1.0000 - val_loss: 1.0252 - val_accuracy: 0.9375\n",
            "Epoch 65/100\n",
            "163/163 [==============================] - 36s 212ms/step - loss: 2.1702e-05 - accuracy: 1.0000 - val_loss: 1.0241 - val_accuracy: 0.9375\n",
            "Epoch 66/100\n",
            "163/163 [==============================] - 35s 206ms/step - loss: 5.2413e-06 - accuracy: 1.0000 - val_loss: 1.0124 - val_accuracy: 0.9375\n",
            "Epoch 67/100\n",
            "163/163 [==============================] - 36s 211ms/step - loss: 2.8183e-06 - accuracy: 1.0000 - val_loss: 1.0209 - val_accuracy: 0.9375\n",
            "Epoch 68/100\n",
            "163/163 [==============================] - 35s 203ms/step - loss: 5.4095e-06 - accuracy: 1.0000 - val_loss: 0.9996 - val_accuracy: 0.9375\n",
            "Epoch 69/100\n",
            "163/163 [==============================] - 38s 227ms/step - loss: 8.8025e-07 - accuracy: 1.0000 - val_loss: 0.9994 - val_accuracy: 0.9375\n",
            "Epoch 70/100\n",
            "163/163 [==============================] - 35s 205ms/step - loss: 3.0546e-06 - accuracy: 1.0000 - val_loss: 0.9986 - val_accuracy: 0.9375\n",
            "Epoch 71/100\n",
            "163/163 [==============================] - 37s 216ms/step - loss: 7.3551e-06 - accuracy: 1.0000 - val_loss: 1.0263 - val_accuracy: 0.9375\n",
            "Epoch 72/100\n",
            "163/163 [==============================] - 35s 209ms/step - loss: 0.0113 - accuracy: 0.9973 - val_loss: 1.4830 - val_accuracy: 0.8125\n",
            "Epoch 73/100\n",
            "163/163 [==============================] - 36s 206ms/step - loss: 0.2060 - accuracy: 0.9682 - val_loss: 6.2448 - val_accuracy: 0.6250\n",
            "Epoch 74/100\n",
            "163/163 [==============================] - 35s 209ms/step - loss: 0.0464 - accuracy: 0.9889 - val_loss: 0.1964 - val_accuracy: 0.8750\n",
            "Epoch 75/100\n",
            "163/163 [==============================] - 37s 217ms/step - loss: 0.0215 - accuracy: 0.9944 - val_loss: 0.1214 - val_accuracy: 0.9375\n",
            "Epoch 76/100\n",
            "163/163 [==============================] - 35s 205ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.5435 - val_accuracy: 0.9375\n",
            "Epoch 77/100\n",
            "163/163 [==============================] - 35s 204ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.8762 - val_accuracy: 0.9375\n",
            "Epoch 78/100\n",
            "163/163 [==============================] - 36s 206ms/step - loss: 4.4444e-04 - accuracy: 0.9996 - val_loss: 0.8671 - val_accuracy: 0.8125\n",
            "Epoch 79/100\n",
            "163/163 [==============================] - 36s 214ms/step - loss: 5.3194e-04 - accuracy: 1.0000 - val_loss: 0.7540 - val_accuracy: 0.9375\n",
            "Epoch 80/100\n",
            "163/163 [==============================] - 35s 204ms/step - loss: 1.7620e-04 - accuracy: 1.0000 - val_loss: 0.9487 - val_accuracy: 0.8750\n",
            "Epoch 81/100\n",
            "163/163 [==============================] - 35s 205ms/step - loss: 4.6809e-04 - accuracy: 0.9998 - val_loss: 0.8870 - val_accuracy: 0.9375\n",
            "Epoch 82/100\n",
            "163/163 [==============================] - 35s 205ms/step - loss: 1.6266e-04 - accuracy: 1.0000 - val_loss: 0.7847 - val_accuracy: 0.9375\n",
            "Epoch 83/100\n",
            "163/163 [==============================] - 37s 216ms/step - loss: 8.3988e-06 - accuracy: 1.0000 - val_loss: 0.7381 - val_accuracy: 0.9375\n",
            "Epoch 84/100\n",
            "163/163 [==============================] - 35s 205ms/step - loss: 9.6617e-06 - accuracy: 1.0000 - val_loss: 0.7594 - val_accuracy: 0.9375\n",
            "Epoch 85/100\n",
            "163/163 [==============================] - 35s 204ms/step - loss: 8.1533e-05 - accuracy: 1.0000 - val_loss: 0.8020 - val_accuracy: 0.9375\n",
            "Epoch 86/100\n",
            "163/163 [==============================] - 38s 226ms/step - loss: 7.6505e-05 - accuracy: 1.0000 - val_loss: 0.7917 - val_accuracy: 0.9375\n",
            "Epoch 87/100\n",
            "163/163 [==============================] - 36s 213ms/step - loss: 2.6970e-05 - accuracy: 1.0000 - val_loss: 0.7112 - val_accuracy: 0.9375\n",
            "Epoch 88/100\n",
            "163/163 [==============================] - 35s 204ms/step - loss: 1.0049e-05 - accuracy: 1.0000 - val_loss: 0.6799 - val_accuracy: 0.9375\n",
            "Epoch 89/100\n",
            "163/163 [==============================] - 35s 204ms/step - loss: 3.5960e-06 - accuracy: 1.0000 - val_loss: 0.6966 - val_accuracy: 0.9375\n",
            "Epoch 90/100\n",
            "163/163 [==============================] - 36s 213ms/step - loss: 1.1164e-05 - accuracy: 1.0000 - val_loss: 0.7635 - val_accuracy: 0.9375\n",
            "Epoch 91/100\n",
            "163/163 [==============================] - 35s 205ms/step - loss: 4.6305e-06 - accuracy: 1.0000 - val_loss: 0.7495 - val_accuracy: 0.9375\n",
            "Epoch 92/100\n",
            "163/163 [==============================] - 38s 226ms/step - loss: 2.1750e-06 - accuracy: 1.0000 - val_loss: 0.7534 - val_accuracy: 0.9375\n",
            "Epoch 93/100\n",
            "163/163 [==============================] - 35s 206ms/step - loss: 2.1249e-06 - accuracy: 1.0000 - val_loss: 0.7533 - val_accuracy: 0.9375\n",
            "Epoch 94/100\n",
            "163/163 [==============================] - 36s 204ms/step - loss: 2.0449e-06 - accuracy: 1.0000 - val_loss: 0.7604 - val_accuracy: 0.9375\n",
            "Epoch 95/100\n",
            "163/163 [==============================] - 37s 208ms/step - loss: 1.3630e-06 - accuracy: 1.0000 - val_loss: 0.7687 - val_accuracy: 0.9375\n",
            "Epoch 96/100\n",
            "163/163 [==============================] - 34s 203ms/step - loss: 2.0197e-06 - accuracy: 1.0000 - val_loss: 0.7560 - val_accuracy: 0.9375\n",
            "Epoch 97/100\n",
            "163/163 [==============================] - 36s 206ms/step - loss: 1.5901e-06 - accuracy: 1.0000 - val_loss: 0.7613 - val_accuracy: 0.9375\n",
            "Epoch 98/100\n",
            "163/163 [==============================] - 34s 203ms/step - loss: 2.2087e-06 - accuracy: 1.0000 - val_loss: 0.7599 - val_accuracy: 0.9375\n",
            "Epoch 99/100\n",
            "163/163 [==============================] - 36s 205ms/step - loss: 1.1044e-06 - accuracy: 1.0000 - val_loss: 0.7622 - val_accuracy: 0.9375\n",
            "Epoch 100/100\n",
            "163/163 [==============================] - 34s 202ms/step - loss: 7.9620e-07 - accuracy: 1.0000 - val_loss: 0.7666 - val_accuracy: 0.9375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Evaluation Code\n",
        "\n",
        "We use the `evaluate` method to assess the model's performance on the test dataset:"
      ],
      "metadata": {
        "id": "zAbiLbBTDdoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.evaluate(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuGGyMzZVFI_",
        "outputId": "d7e0d53d-1821-45ac-91ce-8c54795668fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 3s 88ms/step - loss: 5.6391 - accuracy: 0.7516\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5.639106750488281, 0.7516025900840759]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation Output\n",
        "Upon running the evaluation code, we obtain the following output:\n",
        "\n",
        "20/20 indicates that the evaluation was performed on 20 batches of test data.\n",
        "loss: `5.6391` represents the computed loss value.\n",
        "accuracy: `0.7516` indicates the accuracy of the model on the test dataset.\n",
        "\n",
        "The accuracy has been decreased from our previous model."
      ],
      "metadata": {
        "id": "rBVEkg57Dh8E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Image Classification Model with VGG16 Base\n",
        "\n",
        "We are creating a custom image classification model using the VGG16 architecture as a base model.\n",
        "\n",
        "This custom VGG16-based model differs from the previously built ResNet-based model in terms of architecture. VGG16 is known for its simplicity with a fixed architecture, while ResNet introduces residual blocks to facilitate training of very deep networks.\n",
        "\n",
        "The choice between these models often depends on the specific dataset and problem you are solving. VGG16 can be more suitable for smaller datasets and tasks with moderate complexity, whereas ResNet may excel in very deep networks and complex problems.\n",
        "\n",
        "### Model Architecture\n",
        "\n",
        "1. **Base Model**: We load a pre-trained VGG16 model (excluding the top fully connected layers) using the `VGG16` function with `include_top=False` and `weights='imagenet'`. The input shape is set to `(512, 512, 3)`.\n",
        "\n",
        "2. **Input Layer Modification**: As the VGG16 model expects RGB images with three channels, we create a custom input layer for grayscale images with a single channel. We use a custom layer, `repeat_channels`, to duplicate the single channel into three channels to match the VGG16 input shape.\n",
        "\n",
        "3. **Pass Through Pre-trained Model**: The modified input is passed through the VGG16 base model. The pre-trained layers of VGG16 are frozen, ensuring that their weights remain unchanged during training.\n",
        "\n",
        "4. **Custom Classifier Head**: On top of the base model, we add custom layers for classification:\n",
        "   - Global Average Pooling to reduce the spatial dimensions.\n",
        "   - Multiple dense layers with ReLU activation and dropout for feature extraction and regularization.\n",
        "   - The final output layer with two units for multiclass classification using softmax activation.\n",
        "\n",
        "### Model Compilation\n",
        "\n",
        "We compile the model using the Adam optimizer and categorical cross-entropy loss, suitable for multiclass classification:"
      ],
      "metadata": {
        "id": "2yX2Bic_FHL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = VGG16(include_top=False, weights='imagenet', input_shape=(512, 512, 3))\n",
        "\n",
        "def repeat_channels(x):\n",
        "    return tf.concat([x, x, x], axis=-1)\n",
        "\n",
        "input_layer = Input(shape=(512, 512, 1))\n",
        "\n",
        "rgb_input = Lambda(repeat_channels)(input_layer)\n",
        "\n",
        "x = base_model(rgb_input)\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "predictions = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=predictions)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-38NXrmZWZen",
        "outputId": "b93fc763-f65c-441b-fd30-78678592fd7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 512, 512, 1)]     0         \n",
            "                                                                 \n",
            " lambda_2 (Lambda)           (None, 512, 512, 3)       0         \n",
            "                                                                 \n",
            " vgg16 (Functional)          (None, 16, 16, 512)       14714688  \n",
            "                                                                 \n",
            " global_average_pooling2d_2   (None, 512)              0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 512)               131584    \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,160,066\n",
            "Trainable params: 1,445,378\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Early Stopping and Model Saving\n",
        "\n",
        "In this section, we introduce early stopping as a technique during model training to prevent overfitting and save the trained model after training. Let's break down the key components of this code:\n",
        "\n",
        "### Early Stopping\n",
        "\n",
        "We define an `EarlyStopping` callback, which monitors the validation loss (`val_loss`). If the validation loss does not improve for a specified number of consecutive epochs (`patience`), training will be stopped. The `restore_best_weights` parameter ensures that the model's best weights are restored.\n",
        "\n",
        "### Model Training\n",
        "We use a try-except-finally block to handle model training with early stopping. The model is trained with the fit method, specifying the training dataset, number of epochs, batch size, and validation dataset.\n",
        "\n",
        "We train the model for a maximum of 50 epochs but stop early if the validation loss does not improve for 10 consecutive epochs, as specified by the EarlyStopping callback.\n",
        "The try block captures any potential early stopping triggered by the callback or a manual interruption.\n",
        "In the finally block, we save the trained model to a specified path for later use."
      ],
      "metadata": {
        "id": "NC4Rb9ZOFx_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "#model.fit(train_dataset, epochs=25, validation_data=validation_dataset)\n",
        "#model.save(\"/content/drive/MyDrive/ChestXraay/VGG16_model2.keras\")\n",
        "\n",
        "try:\n",
        "  history = model.fit(train_dataset,\n",
        "                      epochs=50, batch_size=32,\n",
        "                      validation_data = validation_dataset,\n",
        "                      callbacks=[early_stopping])\n",
        "except KeyboardInterrupt:\n",
        "  print(\"\\n\\nTraining Stopped\")\n",
        "finally:\n",
        "  model.save(\"/content/drive/MyDrive/ChestXraay/VGG16_model2.keras\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BqsRJASEKr4",
        "outputId": "bade8b75-d87c-4d74-f2ab-05eba242316d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "163/163 [==============================] - 110s 644ms/step - loss: 0.4386 - accuracy: 0.7937 - val_loss: 0.8380 - val_accuracy: 0.7500\n",
            "Epoch 2/50\n",
            "163/163 [==============================] - 106s 640ms/step - loss: 0.2775 - accuracy: 0.8825 - val_loss: 0.9156 - val_accuracy: 0.6250\n",
            "Epoch 3/50\n",
            "163/163 [==============================] - 106s 641ms/step - loss: 0.2606 - accuracy: 0.8940 - val_loss: 0.6974 - val_accuracy: 0.7500\n",
            "Epoch 4/50\n",
            "163/163 [==============================] - 108s 640ms/step - loss: 0.2438 - accuracy: 0.9032 - val_loss: 0.6966 - val_accuracy: 0.6250\n",
            "Epoch 5/50\n",
            "163/163 [==============================] - 106s 640ms/step - loss: 0.2336 - accuracy: 0.9091 - val_loss: 0.5707 - val_accuracy: 0.7500\n",
            "Epoch 6/50\n",
            "163/163 [==============================] - 106s 639ms/step - loss: 0.2319 - accuracy: 0.9145 - val_loss: 0.5226 - val_accuracy: 0.6875\n",
            "Epoch 7/50\n",
            "163/163 [==============================] - 107s 639ms/step - loss: 0.2119 - accuracy: 0.9224 - val_loss: 0.6926 - val_accuracy: 0.6250\n",
            "Epoch 8/50\n",
            "163/163 [==============================] - 106s 638ms/step - loss: 0.2131 - accuracy: 0.9252 - val_loss: 0.8109 - val_accuracy: 0.6250\n",
            "Epoch 9/50\n",
            "163/163 [==============================] - 106s 638ms/step - loss: 0.1976 - accuracy: 0.9247 - val_loss: 0.7612 - val_accuracy: 0.6250\n",
            "Epoch 10/50\n",
            "163/163 [==============================] - 106s 639ms/step - loss: 0.1967 - accuracy: 0.9247 - val_loss: 0.6473 - val_accuracy: 0.6250\n",
            "Epoch 11/50\n",
            "163/163 [==============================] - 106s 637ms/step - loss: 0.1941 - accuracy: 0.9316 - val_loss: 0.9802 - val_accuracy: 0.6250\n",
            "Epoch 12/50\n",
            "163/163 [==============================] - 107s 639ms/step - loss: 0.1895 - accuracy: 0.9339 - val_loss: 0.9091 - val_accuracy: 0.6250\n",
            "Epoch 13/50\n",
            "163/163 [==============================] - 106s 639ms/step - loss: 0.1816 - accuracy: 0.9354 - val_loss: 0.6631 - val_accuracy: 0.6875\n",
            "Epoch 14/50\n",
            "163/163 [==============================] - 106s 640ms/step - loss: 0.1704 - accuracy: 0.9373 - val_loss: 0.5709 - val_accuracy: 0.7500\n",
            "Epoch 15/50\n",
            "163/163 [==============================] - 107s 639ms/step - loss: 0.1928 - accuracy: 0.9314 - val_loss: 0.7350 - val_accuracy: 0.6250\n",
            "Epoch 16/50\n",
            "163/163 [==============================] - ETA: 0s - loss: 0.1984 - accuracy: 0.9287Restoring model weights from the end of the best epoch: 6.\n",
            "163/163 [==============================] - 106s 641ms/step - loss: 0.1984 - accuracy: 0.9287 - val_loss: 0.7139 - val_accuracy: 0.6250\n",
            "Epoch 16: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Output\n",
        "  - Training continues to epoch 16.\n",
        "  - In this epoch, the training accuracy is approximately 92.87%, and the training loss is 0.1984.\n",
        "  - The validation accuracy remains at 62.50%, and the validation loss is 0.7139.\n",
        "\n",
        "  Training stopped at 16 epochs as the validation loss remains unchanged after 10 iterations."
      ],
      "metadata": {
        "id": "rMRrd4QUGxLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.saving.load_model(\"/content/drive/MyDrive/ChestXraay/VGG16_model2.keras\")"
      ],
      "metadata": {
        "id": "siFC1bJN8eaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrsBQr3p88dB",
        "outputId": "4141f0a6-5196-4f1c-a045-000b5eed512b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "163/163 [==============================] - 132s 639ms/step - loss: 0.2308 - accuracy: 0.9484\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2308228611946106, 0.9484279155731201]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xm-cIq_S9Q1T",
        "outputId": "c37438f6-88c6-46ce-c48d-1f8dd4731877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 25s 1s/step - loss: 0.3642 - accuracy: 0.8125\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.36424189805984497, 0.8125]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Evaluation Code\n",
        "\n",
        "We use the `evaluate` method to assess the model's performance on the test dataset.\n",
        "- 20/20 indicates that the evaluation was performed on 20 batches of test data.\n",
        "- loss: 0.3642 represents the computed loss value.\n",
        "- accuracy: 0.8125 indicates the accuracy of the model on the test dataset.\n",
        "\n",
        "We can see that the accuracy is acheived around one percent extra from our first model which isn't a lot, but when we compare that we have achieved this by using just 16 epochs instead of 100 this does work well compared to our first model.\n",
        "\n",
        "Let's see what happens if change the early stopping by looking at `loss` instead of `val_loss`."
      ],
      "metadata": {
        "id": "A0X_Y-R2Hrs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = VGG16(include_top=False, weights='imagenet', input_shape=(512, 512, 3))\n",
        "\n",
        "def repeat_channels(x):\n",
        "    return tf.concat([x, x, x], axis=-1)\n",
        "\n",
        "input_layer = Input(shape=(512, 512, 1))\n",
        "\n",
        "rgb_input = Lambda(repeat_channels)(input_layer)\n",
        "\n",
        "x = base_model(rgb_input)\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "predictions = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=predictions)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-EoDCJbJArE",
        "outputId": "cc9caf5d-4a50-49db-82dd-f1f1890c5b1e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 4s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 512, 512, 1)]     0         \n",
            "                                                                 \n",
            " lambda (Lambda)             (None, 512, 512, 3)       0         \n",
            "                                                                 \n",
            " vgg16 (Functional)          (None, 16, 16, 512)       14714688  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 512)              0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               131584    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,160,066\n",
            "Trainable params: 1,445,378\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(\n",
        "    monitor='loss',\n",
        "    patience=10,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "#model.fit(train_dataset, epochs=25, validation_data=validation_dataset)\n",
        "#model.save(\"/content/drive/MyDrive/ChestXraay/VGG16_model2.keras\")\n",
        "\n",
        "try:\n",
        "  history = model.fit(train_dataset,\n",
        "                      epochs=50, batch_size=32,\n",
        "                      validation_data = validation_dataset,\n",
        "                      callbacks=[early_stopping])\n",
        "except KeyboardInterrupt:\n",
        "  print(\"\\n\\nTraining Stopped\")\n",
        "finally:\n",
        "  model.save(\"/content/drive/MyDrive/ChestXraay/VGG16_model3.keras\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQOrvk85KO1E",
        "outputId": "c94cbae6-a07f-4f5d-c95a-03dd351ea740"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "163/163 [==============================] - 153s 734ms/step - loss: 0.4316 - accuracy: 0.7968 - val_loss: 0.6619 - val_accuracy: 0.6875\n",
            "Epoch 2/50\n",
            "163/163 [==============================] - 113s 675ms/step - loss: 0.2856 - accuracy: 0.8848 - val_loss: 0.9237 - val_accuracy: 0.5625\n",
            "Epoch 3/50\n",
            "163/163 [==============================] - 112s 676ms/step - loss: 0.2715 - accuracy: 0.8884 - val_loss: 0.7991 - val_accuracy: 0.7500\n",
            "Epoch 4/50\n",
            "163/163 [==============================] - 111s 674ms/step - loss: 0.2306 - accuracy: 0.9116 - val_loss: 0.8481 - val_accuracy: 0.6250\n",
            "Epoch 5/50\n",
            "163/163 [==============================] - 112s 676ms/step - loss: 0.2376 - accuracy: 0.9097 - val_loss: 0.4571 - val_accuracy: 0.7500\n",
            "Epoch 6/50\n",
            "163/163 [==============================] - 112s 675ms/step - loss: 0.2184 - accuracy: 0.9164 - val_loss: 0.8919 - val_accuracy: 0.7500\n",
            "Epoch 7/50\n",
            "163/163 [==============================] - 111s 673ms/step - loss: 0.2257 - accuracy: 0.9145 - val_loss: 0.5249 - val_accuracy: 0.7500\n",
            "Epoch 8/50\n",
            "163/163 [==============================] - 112s 675ms/step - loss: 0.2077 - accuracy: 0.9206 - val_loss: 0.8631 - val_accuracy: 0.6250\n",
            "Epoch 9/50\n",
            "163/163 [==============================] - 112s 675ms/step - loss: 0.2144 - accuracy: 0.9231 - val_loss: 0.7551 - val_accuracy: 0.6250\n",
            "Epoch 10/50\n",
            "163/163 [==============================] - 112s 675ms/step - loss: 0.2210 - accuracy: 0.9233 - val_loss: 0.7758 - val_accuracy: 0.6250\n",
            "Epoch 11/50\n",
            "163/163 [==============================] - 112s 674ms/step - loss: 0.2133 - accuracy: 0.9233 - val_loss: 0.4723 - val_accuracy: 0.6875\n",
            "Epoch 12/50\n",
            "163/163 [==============================] - 112s 676ms/step - loss: 0.2065 - accuracy: 0.9172 - val_loss: 0.7776 - val_accuracy: 0.6250\n",
            "Epoch 13/50\n",
            "163/163 [==============================] - 112s 675ms/step - loss: 0.1930 - accuracy: 0.9312 - val_loss: 0.5842 - val_accuracy: 0.7500\n",
            "Epoch 14/50\n",
            "163/163 [==============================] - 113s 676ms/step - loss: 0.1904 - accuracy: 0.9291 - val_loss: 0.9229 - val_accuracy: 0.6250\n",
            "Epoch 15/50\n",
            "163/163 [==============================] - 112s 678ms/step - loss: 0.1827 - accuracy: 0.9356 - val_loss: 0.4947 - val_accuracy: 0.6875\n",
            "Epoch 16/50\n",
            "163/163 [==============================] - 112s 675ms/step - loss: 0.1741 - accuracy: 0.9363 - val_loss: 0.6760 - val_accuracy: 0.6250\n",
            "Epoch 17/50\n",
            "163/163 [==============================] - 111s 672ms/step - loss: 0.1804 - accuracy: 0.9379 - val_loss: 1.0298 - val_accuracy: 0.6250\n",
            "Epoch 18/50\n",
            "163/163 [==============================] - 111s 673ms/step - loss: 0.1832 - accuracy: 0.9316 - val_loss: 0.6210 - val_accuracy: 0.6250\n",
            "Epoch 19/50\n",
            "163/163 [==============================] - 112s 674ms/step - loss: 0.1806 - accuracy: 0.9352 - val_loss: 0.5082 - val_accuracy: 0.6250\n",
            "Epoch 20/50\n",
            "163/163 [==============================] - 111s 673ms/step - loss: 0.1861 - accuracy: 0.9339 - val_loss: 0.7914 - val_accuracy: 0.6250\n",
            "Epoch 21/50\n",
            "163/163 [==============================] - 112s 675ms/step - loss: 0.1754 - accuracy: 0.9404 - val_loss: 0.5236 - val_accuracy: 0.6250\n",
            "Epoch 22/50\n",
            "163/163 [==============================] - 112s 676ms/step - loss: 0.1683 - accuracy: 0.9410 - val_loss: 0.4702 - val_accuracy: 0.7500\n",
            "Epoch 23/50\n",
            "163/163 [==============================] - 112s 674ms/step - loss: 0.1723 - accuracy: 0.9419 - val_loss: 0.4830 - val_accuracy: 0.7500\n",
            "Epoch 24/50\n",
            "163/163 [==============================] - 113s 674ms/step - loss: 0.1857 - accuracy: 0.9340 - val_loss: 0.4184 - val_accuracy: 0.8125\n",
            "Epoch 25/50\n",
            "163/163 [==============================] - 113s 675ms/step - loss: 0.1861 - accuracy: 0.9316 - val_loss: 0.4005 - val_accuracy: 0.8125\n",
            "Epoch 26/50\n",
            "163/163 [==============================] - 112s 674ms/step - loss: 0.1578 - accuracy: 0.9423 - val_loss: 0.3903 - val_accuracy: 0.8125\n",
            "Epoch 27/50\n",
            "163/163 [==============================] - 112s 676ms/step - loss: 0.1563 - accuracy: 0.9452 - val_loss: 0.4052 - val_accuracy: 0.8125\n",
            "Epoch 28/50\n",
            "163/163 [==============================] - 111s 673ms/step - loss: 0.1557 - accuracy: 0.9452 - val_loss: 0.6972 - val_accuracy: 0.6250\n",
            "Epoch 29/50\n",
            "163/163 [==============================] - 112s 676ms/step - loss: 0.1488 - accuracy: 0.9486 - val_loss: 0.6609 - val_accuracy: 0.6250\n",
            "Epoch 30/50\n",
            "163/163 [==============================] - 112s 675ms/step - loss: 0.1562 - accuracy: 0.9413 - val_loss: 0.2944 - val_accuracy: 0.8125\n",
            "Epoch 31/50\n",
            "163/163 [==============================] - 112s 674ms/step - loss: 0.1595 - accuracy: 0.9457 - val_loss: 0.4843 - val_accuracy: 0.7500\n",
            "Epoch 32/50\n",
            "163/163 [==============================] - 111s 673ms/step - loss: 0.1555 - accuracy: 0.9440 - val_loss: 0.4103 - val_accuracy: 0.8125\n",
            "Epoch 33/50\n",
            "163/163 [==============================] - 111s 674ms/step - loss: 0.1503 - accuracy: 0.9479 - val_loss: 0.5325 - val_accuracy: 0.8125\n",
            "Epoch 34/50\n",
            "163/163 [==============================] - 112s 674ms/step - loss: 0.1659 - accuracy: 0.9425 - val_loss: 0.3683 - val_accuracy: 0.8125\n",
            "Epoch 35/50\n",
            "163/163 [==============================] - 112s 675ms/step - loss: 0.1587 - accuracy: 0.9433 - val_loss: 0.6674 - val_accuracy: 0.6250\n",
            "Epoch 36/50\n",
            "163/163 [==============================] - 112s 674ms/step - loss: 0.1604 - accuracy: 0.9419 - val_loss: 0.6505 - val_accuracy: 0.6250\n",
            "Epoch 37/50\n",
            "163/163 [==============================] - 112s 674ms/step - loss: 0.1656 - accuracy: 0.9413 - val_loss: 0.4451 - val_accuracy: 0.6875\n",
            "Epoch 38/50\n",
            "163/163 [==============================] - 113s 676ms/step - loss: 0.1529 - accuracy: 0.9465 - val_loss: 0.3652 - val_accuracy: 0.8125\n",
            "Epoch 39/50\n",
            "163/163 [==============================] - 112s 675ms/step - loss: 0.1483 - accuracy: 0.9477 - val_loss: 0.4931 - val_accuracy: 0.6875\n",
            "Epoch 40/50\n",
            "163/163 [==============================] - 112s 675ms/step - loss: 0.1354 - accuracy: 0.9536 - val_loss: 0.4149 - val_accuracy: 0.7500\n",
            "Epoch 41/50\n",
            "163/163 [==============================] - 111s 673ms/step - loss: 0.1402 - accuracy: 0.9517 - val_loss: 0.3747 - val_accuracy: 0.8125\n",
            "Epoch 42/50\n",
            "163/163 [==============================] - 112s 674ms/step - loss: 0.1694 - accuracy: 0.9394 - val_loss: 0.4095 - val_accuracy: 0.8125\n",
            "Epoch 43/50\n",
            "163/163 [==============================] - 111s 673ms/step - loss: 0.1487 - accuracy: 0.9482 - val_loss: 0.3470 - val_accuracy: 0.8125\n",
            "Epoch 44/50\n",
            "163/163 [==============================] - 112s 675ms/step - loss: 0.1483 - accuracy: 0.9507 - val_loss: 0.3355 - val_accuracy: 0.8125\n",
            "Epoch 45/50\n",
            "163/163 [==============================] - 112s 674ms/step - loss: 0.1534 - accuracy: 0.9469 - val_loss: 0.3286 - val_accuracy: 0.8125\n",
            "Epoch 46/50\n",
            "163/163 [==============================] - 112s 674ms/step - loss: 0.1710 - accuracy: 0.9438 - val_loss: 0.3336 - val_accuracy: 0.7500\n",
            "Epoch 47/50\n",
            "163/163 [==============================] - 111s 673ms/step - loss: 0.1711 - accuracy: 0.9408 - val_loss: 0.4474 - val_accuracy: 0.8125\n",
            "Epoch 48/50\n",
            "163/163 [==============================] - 112s 673ms/step - loss: 0.1774 - accuracy: 0.9388 - val_loss: 0.4342 - val_accuracy: 0.8125\n",
            "Epoch 49/50\n",
            "163/163 [==============================] - 112s 676ms/step - loss: 0.1620 - accuracy: 0.9429 - val_loss: 0.3886 - val_accuracy: 0.8125\n",
            "Epoch 50/50\n",
            "163/163 [==============================] - ETA: 0s - loss: 0.1542 - accuracy: 0.9444Restoring model weights from the end of the best epoch: 40.\n",
            "163/163 [==============================] - 111s 673ms/step - loss: 0.1542 - accuracy: 0.9444 - val_loss: 0.4382 - val_accuracy: 0.6875\n",
            "Epoch 50: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVUgmzRHkr0q",
        "outputId": "e029a68b-c669-4498-db89-35b20f3c262b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 15s 662ms/step - loss: 0.3649 - accuracy: 0.8109\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3648855686187744, 0.8108974099159241]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the accuracy on test dataset hasn't increased after running for full 50 epochs, so we'll take our previous model as final model with 81% accuracy."
      ],
      "metadata": {
        "id": "x3j6DZjok9Rd"
      }
    }
  ]
}